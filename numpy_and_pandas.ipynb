{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Numpy 和Pandas 基础\n",
        "\n",
        "## Numpy 基础\n",
        "\n",
        "### 创建数组\n",
        "有许多种方法创建数组，下面是一些简单的例子，使用`np.array()`函数，将列表、元组转化为数组："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3, 4])\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "注意，与列表不同，Numpy数组只能包含相同类型的数据，下面的例子中，`np.array()`函数自动将列表中的整数转换为浮点数："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "b = np.array([3.14, 4, 2, 3])\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "列表总是一维的，Numpy数组可以是多维的，例如下面的例子使用："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = np.array([[1.5, -0.1, 3],\n",
        "                [0, -3, 6.5]])\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "数组`data`是二维数组，可以查看属性`ndim`和`shape`："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.ndim\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可以对`data`进行通常的数学运算："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(data * 10)\n",
        "print(data + data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Numpy也有函数来生成一些特定格式的数组,如表 @tbl-array-creats 所示：\n",
        " \n",
        ": Numpy中生成数组的函数 {#tbl-array-creats}\n",
        "\n",
        "| 函数名            | 描述                                                                                      |\n",
        "|-------------------|-------------------------------------------------------------------------------------------|\n",
        "| `array `            | 将输入数据（列表、元组、数组或其他序列类型）转换为 ndarray，可以自动推断或显式指定数据类型；默认会复制输入数据 |\n",
        "| `asarray`           | 将输入转换为 ndarray，如果输入已经是 ndarray，则不会进行复制                              |\n",
        "| `arange`            | 类似于内置的 range，但返回的是 ndarray 而不是列表                                         |\n",
        "| `ones`, `ones_like`   | 生成给定形状和数据类型的全 1 数组；ones_like 以另一个数组为模板，生成相同形状和数据类型的全 1 数组 |\n",
        "| `zeros`, `zeros_like` | 类似于 `ones` 和 `ones_like`，但生成的是全 0 数组                                              |\n",
        "| `empty`, `empty_like` | 通过分配新内存创建新数组，但不会像 ones 和 zeros 那样填充值                                |\n",
        "| `full`, `full_like`   | 生成给定形状和数据类型的数组，所有值都设置为指定的“填充值”；`full_like` 以另一个数组为模板，生成相同形状和数据类型的填充值数组 |\n",
        "| `eye`,` identity`     | 生成单位矩阵（对角线为 1，其余为 0）         \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "zeros = np.zeros(10)\n",
        "print(zeros)\n",
        "ones = np.ones((2,3), dtype=float)\n",
        "print(ones)\n",
        "# 单位矩阵\n",
        "idents = np.identity(3)\n",
        "print(idents)\n",
        "\n",
        "evens = np.arange(0, 20, 2)\n",
        "print(evens)\n",
        "grids = np.linspace(0, 1, 21)\n",
        "print(grids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Numpy中random子库包含丰富的生成随机数的函数，例如："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#生成正态分布\n",
        "nums_norm = np.random.normal(loc=0, scale=1, size=(4, 3))\n",
        "print(nums_norm)\n",
        "nums_int = np.random.randint(low=1, high=11, size=(2, 10))\n",
        "print(nums_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 数组的索引\n",
        "\n",
        "注意索引与列表一样，从0开始；选择元素时不包括右侧。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "z = np.array((1,2,3,4,5))\n",
        "z[0]\n",
        "z[0:2]\n",
        "z[-1]\n",
        "z[::2]\n",
        "z[::-1]\n",
        "# 2D arrays\n",
        "z = np.array([[1,2],\n",
        "              [3, 4]])\n",
        "z[0,0]\n",
        "z[0,:]\n",
        "z[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 数组方法\n",
        "\n",
        "数组方法众多，例如：\n",
        "\n",
        "代码段"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "a = np.array((4,3,2,1))\n",
        "a.sort()\n",
        "\n",
        "a.sum()\n",
        "a.mean()\n",
        "a.max()\n",
        "a.min()\n",
        "a.var()\n",
        "a.std()\n",
        "a.argmax()\n",
        "a.cumsum()\n",
        "a.cumprod()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 数组的数学运算\n",
        "\n",
        "注意，运算符 `+`, `-` , `*`, `/` 和 `**`，都是逐元素运算。例如："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "a = np.array([1,2,3,4])\n",
        "b = np.array([5,6,7,8])\n",
        "a + b\n",
        "a * b\n",
        "a + 10\n",
        "a * 10\n",
        "# 2D array\n",
        "A = np.ones((2,2))\n",
        "B = np.ones((2,2))\n",
        "A + B\n",
        "A+10\n",
        "A * B\n",
        "(A+1) ** 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可以使用 @ 或 np.dot() 进行矩阵乘法。如果是向量则计算内积。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "A = np.array([[1,2],\n",
        "              [3,4]])\n",
        "B = np.array([[5,6,],\n",
        "              [7,8]])\n",
        "A@B\n",
        "#or\n",
        "np.dot(A,B)\n",
        "#\n",
        "b = np.array([0, 1])\n",
        "A@b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 例：多项式计算\n",
        "Numpy中有一些列简便运算的函数。例如 `np.poly1d()`，多项式求和:\n",
        "\n",
        "$$p(x) = a_{0} + a_{1}x + a_{2}x^{2} + \\cdots + a_{N}x^{N} = \\sum_{n=0}^{N}a_{n}x^{n} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = np.poly1d([1,2,3])\n",
        "print(p)\n",
        "print(p(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "注意，`np.poly1d()` 函数高阶项在前面。\n",
        "\n",
        "利用向量计算，自定义一个函数："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def poly1d(x, coef):\n",
        "    X = np.ones_like(coef)\n",
        "    X[1:] = x\n",
        "    y = np.cumprod(X) # y = [1,x,x**2,...]\n",
        "    return coef @ y[::-1]\n",
        "\n",
        "coef = [1, 2, 3]\n",
        "poly1d(2, coef=coef)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random子库\n",
        "\n",
        "Numpy中有大量的与随机数生成器有关的函数。\n",
        "\n",
        "下面是一个例子，注意，没有设定随机种子数，因此每次运行结果会不同。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define an array of choices\n",
        "choices = np.array(['apple', 'banana', 'orange', 'grape', 'kiwi'])\n",
        "\n",
        "# Perform random choice\n",
        "random_choice = np.random.choice(choices)\n",
        "\n",
        "# Print the random choice\n",
        "print(random_choice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 例：简单的随机游走"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 设置随机种子以便复现\n",
        "np.random.seed(0)\n",
        "\n",
        "# 步数\n",
        "n_steps = 1000\n",
        "\n",
        "# 生成每一步的随机步长（-1 或 1）\n",
        "steps = np.random.choice([-1, 1], size=n_steps)\n",
        "\n",
        "# 计算随机游走序列\n",
        "walk = np.cumsum(steps)\n",
        "\n",
        "# 绘制线形图\n",
        "plt.plot(walk)\n",
        "plt.title('Random Walk')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Position')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 例：利用随机数模拟中心极限定理\n",
        "\n",
        "中心极限定理 (Central Limit Theorem, CLT) 是概率论中一个非常强大的定理。它指出，当从任何形状的总体中抽取足够大的独立同分布 (i.i.d.) 样本时，这些样本均值的分布将近似于正态分布，无论原始总体分布如何。样本量越大，近似程度越好。\n",
        "\n",
        "我们将通过以下步骤来模拟验证 CLT：\n",
        "\n",
        "- 选择一个非正态分布的总体: 比如，一个指数分布或均匀分布，它们的形状都不是钟形的。\n",
        "- 设置样本参数: 定义每次抽样的样本大小 (sample_size) 和重复抽样的次数 (num_samples)。\n",
        "- 重复抽样并计算均值: 从总体中抽取 num_samples 次样本，每次抽取 sample_size 个数据点，并计算每次抽样的平均值。\n",
        "- 可视化: 绘制样本均值的直方图，并与原始总体分布的直方图进行对比。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family'] = 'SimHei'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. 设置模拟参数 ---\n",
        "population_size = 1000000  # 原始总体的大小\n",
        "sample_size = 30           # 每次抽样的样本量 (通常大于30就被认为是“大样本”)\n",
        "num_samples = 10000        # 重复抽样的次数，即我们将有多少个样本均值\n",
        "np.random.seed(123)\n",
        "\n",
        "# --- 2. 选择一个非正态分布的总体 (例如：指数分布) ---\n",
        "# 指数分布 (Exponential Distribution) 是一种偏态分布，非常适合验证CLT\n",
        "# numpy.random.exponential(scale=1.0, size=None)\n",
        "# scale 参数是均值，这里我们设置均值为2.0\n",
        "population_data = np.random.exponential(scale=2.0, size=population_size)\n",
        "# 也可以用均匀分布作为总体进行验证\n",
        "# population_data_uniform = np.random.uniform(low=0.0, high=10.0, size=population_size)\n",
        "\n",
        "# --- 3. 重复抽样并计算均值 ---\n",
        "sample_means = []\n",
        "for _ in np.arange(num_samples):\n",
        "    # 从总体中随机抽取 sample_size 个数据点\n",
        "    sample = np.random.choice(population_data, size=sample_size, replace=True)\n",
        "    # 计算样本的均值并添加到列表中\n",
        "    sample_means.append(np.mean(sample))\n",
        "\n",
        "# 将样本均值列表转换为 NumPy 数组，方便后续处理和绘图\n",
        "sample_means = np.array(sample_means)\n",
        "\n",
        "# --- 4. 可视化结果 ---\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# 绘制原始总体分布的直方图\n",
        "plt.subplot(2, 1, 1) # 1行2列的第一个图\n",
        "plt.hist(population_data, bins=50, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.title(f'原始总体分布 (指数分布)\\n均值: {np.mean(population_data):.2f}, 标准差: {np.std(population_data):.2f}')\n",
        "plt.xlabel('值')\n",
        "plt.ylabel('频率密度')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "# 绘制样本均值分布的直方图\n",
        "plt.subplot(2, 1, 2) # 1行2列的第二个图\n",
        "plt.hist(sample_means, bins=50, density=True, color='lightcoral', edgecolor='black', alpha=0.7)\n",
        "plt.title(f'样本均值的分布 ({sample_size}个样本量，重复{num_samples}次)\\n均值: {np.mean(sample_means):.2f}, 标准差: {np.std(sample_means):.2f}')\n",
        "plt.xlabel('样本均值')\n",
        "plt.ylabel('频率密度')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.tight_layout() # 调整子图布局，避免重叠\n",
        "plt.show()\n",
        "\n",
        "# --- 5. 额外验证：比较均值和标准差 ---\n",
        "print(\"\\n--- 模拟结果验证 ---\")\n",
        "print(f\"原始总体的均值 (μ): {np.mean(population_data):.4f}\")\n",
        "print(f\"原始总体的标准差 (σ): {np.std(population_data):.4f}\")\n",
        "print(f\"样本均值的均值 (μ_x̄): {np.mean(sample_means):.4f}\")\n",
        "# 根据中心极限定理，样本均值的标准差 (标准误差) 应该约等于 总体标准差 / sqrt(样本量)\n",
        "expected_std_of_means = np.std(population_data) / np.sqrt(sample_size)\n",
        "print(f\"样本均值的标准差 (σ_x̄): {np.std(sample_means):.4f}\")\n",
        "print(f\"理论上样本均值的标准差 (σ / sqrt(n)): {expected_std_of_means:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 通用函数\n",
        "\n",
        "Numpy中许多函数是通用函数(universal functions)，是一种在 ndarray 数据中进行逐元素操作的函数，大多数数学函数属于此类。\n",
        "\n",
        "例如 `np.cos()` 函数："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.cos(1.0)\n",
        "np.cos(np.linspace(0, 1, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "例如，我们想计算$\\frac{0}{1},\\frac{1}{2},\\cdots, \\frac{4}{5}$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.arange(5) / np.arange(1, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ": Numpy中算术运算子和函数 {#tbl-array-operators}\n",
        "\n",
        "| 运算符 | 对应的 ufunc         | 描述                   | 示例                  |\n",
        "|--------|---------------------|------------------------|-----------------------|\n",
        "| +      | np.add              | 加法                   | 1 + 1 = 2             |\n",
        "| -      | np.subtract         | 减法                   | 3 - 2 = 1             |\n",
        "| -      | np.negative         | 一元取反                | -2                    |\n",
        "| *      | np.multiply         | 乘法                   | 2 * 3 = 6             |\n",
        "| /      | np.divide           | 除法                   | 3 / 2 = 1.5           |\n",
        "| //     | np.floor_divide     | 向下取整除法            | 3 // 2 = 1            |\n",
        "| **     | np.power            | 幂运算                 | 2 ** 3 = 8            |\n",
        "| %      | np.mod              | 取模/余数              | 9 % 4 = 1             |\n",
        "\n",
        "### 例：通用函数\n",
        "\n",
        "考察最大化函数 $f(x,y)$ 在区间 $ [−a,a] \\times [−a, a]$ 上的最大值：\n",
        "$$\n",
        "f(x,y)= \\frac{cos(x^{2} + y^{2})}{1 + x^2 + y^2} \n",
        "$$ \n",
        "​\n",
        "令$a=3$。\n",
        "我们定义一个函数，然后生成数组，计算对应的-值，通过栅格（grid）搜索最大值（等于1）。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def f(x, y):\n",
        "    return np.cos(x**2 + y**2) / (1 + x**2 + y**2)\n",
        "\n",
        "grid = np.linspace(-3, 3, 50)\n",
        "x, y = np.meshgrid(grid, grid)\n",
        "z = f(x, y)\n",
        "\n",
        "# 最大值\n",
        "max_value = np.max(z)\n",
        "print(\"函数的最大值:\", max_value)\n",
        "\n",
        "# 绘制3D图像\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(x, y, z, cmap='viridis')\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_zlabel('f(x, y)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "图示\n",
        "\n",
        "### 例：洛伦茨曲线和基尼系数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np # 载入numpy库\n",
        "def lorenz_curve(y):\n",
        "    n = len(y)\n",
        "    y = np.sort(y) # 从小到大排序\n",
        "    s = np.zeros(n + 1) # 生成n+1 个数值零\n",
        "    s[1:] = np.cumsum(y) # 从第2个数（索引1）累计求和，使第一个数据点为（0，0）\n",
        "    cum_people = np.linspace(0, 1, n + 1)\n",
        "    cum_income = s / s[n] # s[n]为最后的值，即所有值的和\n",
        "    return cum_people, cum_income"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n = 2000\n",
        "np.random.seed(1)\n",
        "sample = np.exp(np.random.randn(n))\n",
        "f_vals, l_vals = lorenz_curve(sample)\n",
        "#\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "ax.plot(f_vals, l_vals, label=f'lognormal sample', lw = 2)\n",
        "ax.plot([0, 1], [0, 1], label='equality', lw = 2)\n",
        "ax.fill_between(f_vals,l_vals, f_vals, alpha=0.06)\n",
        "ax.fill_between(f_vals, l_vals, np.zeros_like(f_vals),alpha=0.06)\n",
        "ax.vlines([0.8], [0], [0.43], linestyles='--', colors='gray')\n",
        "ax.hlines([0.43], [0], [0.8], linestyles='--', colors='gray')\n",
        "ax.set_xlim((0,1))\n",
        "ax.set_ylim((0,1))\n",
        "ax.text(0.55, 0.4,\"A\", fontsize=16)\n",
        "ax.text(0.75,0.15,\"B\",fontsize=16)\n",
        "ax.set_xlabel('Cumulative share of people')\n",
        "ax.set_ylabel('Cumulative share of income')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 基尼系数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def gini(y):\n",
        "    n = len(y)\n",
        "    y_1 = np.reshape(y, (n, 1))\n",
        "    y_2 = np.reshape(y, (1, n))\n",
        "    g_sum = np.sum(np.abs(y_1 - y_2)) # 利用了numpy的广播（broadcasting）\n",
        "    return g_sum / (2 * n * np.sum(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 模拟对数正态数据\n",
        "np.random.seed(1)\n",
        "k = 5\n",
        "sigmas = np.linspace(0.2, 4, k)\n",
        "n = 2000\n",
        "ginis = []\n",
        "for sigma in sigmas:\n",
        "    mu = -sigma ** 2 / 2\n",
        "    y = np.exp(mu + sigma * np.random.randn(n))\n",
        "    ginis.append(gini(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "ax.plot(sigmas, ginis, marker = 'o',label='simulated', lw = 2)\n",
        "ax.set_xlabel('Standard deviation')\n",
        "ax.set_ylabel('Gini coefficient')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pandas 基础\n",
        "\n",
        "Pandas是数据分析最常用的包:\n",
        "\n",
        "- Pandas 定义了处理数据的结构；\n",
        "- 数据处理：读取、调整指数、日期和时间序列、排序、分组、处理缺失值；\n",
        "- 一些更复杂的统计功能，如 statsmodels 和 scikit-learn，也是建立在pandas基础上。\n",
        "\n",
        "### Pandas中的序列和数据框\n",
        "\n",
        "Pandas中两类数据，Series 和 DataFrame；\n",
        "\n",
        "Series 基于Numpy数组，支持许多类似运算；\n",
        "\n",
        "Series 可以看作一“列”数据；\n",
        "\n",
        "DataFrame 可以看作储存相应列数据的二维对象；类似Excel表单；\n",
        "\n",
        "Series一些方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "np.random.seed(123)\n",
        "s = pd.Series(np.random.randn(100), name=\"daily return\")\n",
        "s.plot();\n",
        "np.abs(s)\n",
        "s.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DataFrames 是几列数据组成，每一列对应一个变量；\n",
        "\n",
        "用来方便的处理行和列组织的数据；索引（index）对应行，变量列名（columns）对应列；\n",
        "\n",
        "可以读取各类软件格式存储数据，csv, excel, stata, html, json,sql等；\n",
        "\n",
        "\n",
        "## 应用：Penn World Table\n",
        "\n",
        "这一部分应用[Penn World Table](https://www.rug.nl/ggdc/productivity/pwt/)介绍对原始数据的一些常见处理方法。该数据集当前版本为PWT 10.01，包含183个国家1950-2019年的收入、产出、投入和生产率等指标，详细介绍可参见[User Guide to PWT 10.0 data files](https://www.rug.nl/ggdc/docs/pwt100-user-guide-to-data-files.pdf)。数据背后的方法、理论及使用建议，可参见 @feenstra2015next。\n",
        "\n",
        "网站提供了Stata和Excel格式数据，这里我们下载了后者。数据本身是一个面板数据（Panel Data），“国家 - 年” 唯一识别一个观测值。我们从截面数据入手先只保留2019年数据， 然后再看更复杂的情况。\n",
        "\n",
        "### 导入数据\n",
        "\n",
        "假设数据保存在当前路径的datasets子文件中："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "pwt = pd.read_excel(io = \"datasets/pwt1001.xlsx\",\n",
        "                header=0,                \n",
        "                sheet_name=\"Data\")\n",
        "# 保留2019年数据\n",
        "pwt2019 = pwt[pwt['year'] == 2019].copy().drop(labels='cor_exp',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "注意其中的几个参数，`io`是文件路径；`header`表明列标题行，这里是第一行；`sheet_name`是数据所在表单名；将载入的数据赋值给pwt数据框。我们只保留2019年的观测值，变量`cor_exp`在这一年全部为缺失值，这里直接删除了。\n",
        "\n",
        "先为`pwt2019`数据框设置索引变量，这里使用国家名代码变量（countrycode）："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.set_index('countrycode', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可以`df.info()`概率数据集，或者使用`df.head()`或`df.tail()`查看头部和尾部观测值："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.info()\n",
        "pwt2019.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "默认显示5条观测值，如果希望看到更多观测值，可以使用 `df.tail(n=10)` 修改数值。\n",
        "\n",
        "可以应用`.shape, .ndim`,`.columns`等属性查看基本信息，可以看到数据集包含51个变量共183个观测值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(pwt2019.shape)\n",
        "print(pwt2019.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 选择观测值和变量\n",
        "\n",
        "应用中经常对某些观测值或特定子集进行操作，因此很重要的一步是选择观测值和变量。\n",
        "\n",
        "最基本的方法可以通过Python数组的切片（slicing）方式选择特定的**行**。例如，选择第3至5个观测值："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019[2:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "要选择**列**，可以用包含列名字的列表："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vars_selected = ['country', 'rgdpe', 'rgdpo', 'pop', 'emp', 'cgdpe', 'cgdpo', 'ctfp' ]\n",
        "df = pwt2019[vars_selected]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `.loc`方法\n",
        "\n",
        "`.loc` 是基于 标签（label-based） 的数据选择方法。这意味着你使用行和列的实际标签名来选择数据，而不是它们的整数位置。\n",
        "\n",
        "例如，要选择金砖国家（BRICKS）的观测值："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bricks = ['CHN', 'BRA', 'RUS', 'IND', 'ZAF']\n",
        "pwt2019.loc[bricks]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "或者选择列："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "variables = ['country', 'rgdpe', 'pop']\n",
        "pwt2019.loc[:, variables]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "或者同时指定行和列："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.loc[bricks, variables]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `.iloc`方法\n",
        "\n",
        "相应的，`.iloc` 是基于整数位置（integer-location based）的，使用行和列的整数位置（从 0 开始）来选择数据。例如："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 选择第2行数据（索引位置为1）\n",
        "pwt2019.iloc[1]\n",
        "# 选择第1行（索引为0）、第3行（索引为2）和第5行（索引为4）\n",
        "pwt2019.iloc[[0, 2, 4]]\n",
        "# 选择前5行、第4至第6列观测值\n",
        "pwt2019.iloc[:5, 3:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "这里需要注意Python中索引位置。Python中进行切片（slicing）操作时，语法通常类似 `[start:end]`，要注意：\n",
        "\n",
        "- `start`：切片的起始索引，对应的元素会被包含。\n",
        "- `end`：切片的结束索引，对应的元素不会被包含。\n",
        "  \n",
        "#### 根据条件筛选\n",
        "\n",
        "除了根据索引或位置选择数据外，也可以利用条件来筛选观测值。例如，根据人口变量（`pop`，单位：百万）选择2019年总人口超过2亿的观测值："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019[pwt2019['pop'] >= 200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "注意，`pwt2019['pop'] >= 200` 的结果是一列布林值，然后`pwt2019[]`选择返回取值为`True`的观测值。\n",
        "\n",
        "再例如，下面的代码包含了两个条件：\n",
        "\n",
        "- 国家名属于金砖国家。注意这里使用了Pandas 中的`df.isin()`函数；\n",
        "- 2019年人口超过10亿。\n",
        "  \n",
        "当有不止一个条件时，我们用`&`, `|`表示`and` 和 `or`运算符；"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "BRICKS = ['China','Brazil',  ' Russian Federation', 'India', 'South Africa']\n",
        "#\n",
        "pwt2019[(pwt2019['country'].isin(BRICKS)) & (pwt2019['pop'] > 1000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "更复杂的情况，可以在条件语句中加入数学表达式。例如，下面的代码筛选了人均实际GDP超过2万美元和人口超过5000万的国家的观测值，这里人均实际GDP是购买力平价调整后支出法衡量的实际GDP与人口的比值："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019[(pwt2019['rgdpe']/pwt2019['pop'] > 20000) & (pwt2019['pop'] > 50)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### apply 方法\n",
        "\n",
        "Pandas中一个广泛应用的方法是 `df.apply()`，它将一个函数应用到每一行/列，返回一个序列；\n",
        "\n",
        "函数可以是内嵌的（built in）也可以是自定义的，例如，计算每一列的最大值，为了节省输出空间，使用子集`df`数据框："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.apply(np.max, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "或者，自定义一个函数`range(x)`计算极差："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "def range(x):\n",
        "    return np.max(x) - np.min(x)\n",
        "df.select_dtypes(np.number).apply(range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "再例如，归一化（normalization）经常使用minmax方法：\n",
        "$$\n",
        "Y = \\frac{X_{i} - \\min(X_{i})}{\\max(X_{i}) - \\min(X_{i})}\n",
        "$$\n",
        "\n",
        "我们定义一个函数`minmax()`，然后应用`apply()`方法："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def minmax(S):\n",
        "    return (S-S.min())/(S.max() - S.min())\n",
        "pwt2019[['pop','rgdpe', 'emp']].apply(minmax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "经常将`lambda`函数方法与`df.apply()`方法相结合。例如，数据集中有4个指标度量GDP，分别是`['rgdpe', 'rgdpo','cgdpe','cgdpo']`，假设我们希望计算一个加权平均数，权重为（0.3，0.2，0.3，0.2）："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "variables = ['rgdpe', 'rgdpo','cgdpe','cgdpo']\n",
        "df[variables].apply(lambda row:\n",
        "    row['rgdpe']*0.3 + row['rgdpo']*0.2 + row['cgdpe']*0.3 + row['cgdpo']*0.2,\n",
        "    axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "注意，z选项`axis = 1` ，将函数应用至每一行，默认值为0。\n",
        "\n",
        "\n",
        "### 检测和处理缺失值\n",
        "\n",
        "Pandas中最常用的缺失值表示是`NaN`（Not a Number）。可以使用`isnull()`或`isna()`函数检测缺失值，返回一个布尔型的DataFrame，其中`True`表示缺失值："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.isna()\n",
        "#pwt2019.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "下面的的代码计算了缺失值的数量，将其除以样本容量得到缺失值比例，然后按照降序排序，并将比例最高的前15个变量绘制柱形图："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "(pwt2019.isna().sum()/pwt2019.shape[0]*100).sort_values(ascending=False)[:15].plot(kind='bar', ax=ax)\n",
        "ax.set_ylabel(\"%\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "另一种图示的方法是类似矩阵绘图的方式，将缺失值标记出来，`missingno`库有简单的命令实现："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import missingno as msno\n",
        "plt.figure(figsize=(12, 6))\n",
        "msno.matrix(pwt2019)\n",
        "plt.title(\"Missing Values Matrix\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**删除缺失值**\n",
        "\n",
        "处理缺失值的方法有很多种，选择哪种方法取决于你的数据特性、缺失原因以及分析目标。最直接的方法是使用`df.dropna()`函数删除包含缺失值的行或列："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 删除含缺失值的行\n",
        "pwt2019.dropna()\n",
        "# 删除含缺失值的列\n",
        "pwt2019.dropna(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "另外，上面的命令并没有改变原数据框，可以通过赋值方式保存。或者加上选项`df.dropna(inplace=True)`，即在原数据框中生效。\n",
        "\n",
        "**填充**\n",
        "\n",
        "`df.fillna()`是用于填充缺失值的核心函数。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#\n",
        "pwt2019.fillna(0)\n",
        "#\n",
        "pwt2019.select_dtypes(np.number).fillna(0).combine_first(pwt2019)\n",
        "pwt2019.select_dtypes(np.number).fillna(pwt2019.mean(numeric_only=True)).combine_first(pwt2019)\n",
        "pwt2019.select_dtypes(np.number).fillna(pwt2019.median(numeric_only=True)).combine_first(pwt2019)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#pwt2019.fillna(method='ffill')\n",
        "pwt2019.fillna(method='bfill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**插值法（Interpolation）**\n",
        "\n",
        "除了填充给定值以外，也有更复杂的插值法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.interpolate(method=\"linear\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "更复杂的方法涉及到模型估计问题，如KNN预测等。Scikit-learn库有专门的方法，这里就不多涉及。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer_mean = SimpleImputer(strategy='mean')\n",
        "pd.DataFrame(imputer_mean.fit_transform(pwt2019.select_dtypes(np.number)), columns=pwt2019.select_dtypes(np.number).columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 缩尾处理\n",
        "\n",
        "应用中，常需要对异常值进行一定的处理，其中一种方法是缩尾处理（Winsorize），将极端值替换为某个百分位数的值，例如，将上限设为 99 百分位数，下限设为 1 百分位数。\n",
        "\n",
        "可以使用`df.clip()`函数实现，例如全要素生产率水平`ctfp`："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "q95 = pwt2019['ctfp'].quantile(0.95)\n",
        "q05 = pwt2019['ctfp'].quantile(0.05)\n",
        "\n",
        "pwt2019['ctfp'].dropna().clip(lower=q05, upper=q95, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 观测值排序\n",
        "\n",
        "有时候需要对数据集进行一定的排序，Pandas中可以按索引(`df.sort_index`)和值（`df.sort_values`）排序。\n",
        "\n",
        "例如，将索引按降序排序，这里的索引是国家代码，因此升序/降序是按照字母顺序："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.sort_index(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "来看`df.sort_values`的例子，假设我们希望按2019年的人均GDP（PPP链式调整后）降序排列："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019['rgdp_per'] = pwt2019['rgdpe']/pwt2019['pop']\n",
        "pwt2019.sort_values(by='rgdp_per', ascending=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 数据集合并\n",
        "\n",
        "实际应用中，数据可能来自不同的来源，经常需要合并数据集，`pd.merge()`函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import wbgapi as wb\n",
        "inf = wb.data.DataFrame(series='NY.GDP.DEFL.KD.ZG', time='2019')\n",
        "pd.merge(df[['country','pop','emp']], inf, left_index=True, right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 多级索引\n",
        "\n",
        "这里的数据是一个面板数据，“国家-年”对应一个观测值，可以利用Pandas的多级索引功能，详见Pandas文档[MultiIndex / advanced indexing](https://pandas.pydata.org/docs/dev/user_guide/advanced.html#)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt = pd.read_excel(io = \"datasets/pwt1001.xlsx\",\n",
        "                header=0,                \n",
        "                sheet_name=\"Data\")\n",
        "pwt.set_index(['countrycode','year'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们可以使用`.loc()`方法选择需要的数据，例如："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 中国子集\n",
        "df_china = pwt.loc['CHN']\n",
        "# 中国、美国子集\n",
        "df_china_us = pwt.loc[['CHN','USA']]\n",
        "# 变量子集\n",
        "df_sub_china_us = pwt.loc[['CHN', 'USA']][['rgdpe','rgdpo']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "如果需要选择某一年的截面数据："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.loc[(slice(None), [2019]), :]\n",
        "# 1992年之后的数据\n",
        "pwt.loc[(slice(None), slice(1992, None)), :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "这里使用了`df.loc`结合`slice`函数的方法，注意：\n",
        "\n",
        "- `slice(None)`: 这表示选择 所有 `countrycode`。\n",
        "- `slice(1992, None)`: 这表示从 `year` 的 1992年 开始，选择到 **所有**后续年份。由于索引是排序的（通常情况下），这有效地选择了所有 `year > 1992` 的数据。\n",
        "- `:`表示选择所有列。\n",
        "\n",
        "上面的例子使用`slice`函数不是那么直观，也可以使用`df.index.get_level_values('year')`提取索引`year`的值，形成一个序列（可以另存为一个变量），然后利用表达式生成一个布尔序列，对数据框进行筛选："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt[pwt.index.get_level_values('year') > 1992]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "当然，可以同时选择指定的变量和年份，例如："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.loc[(slice(None),[2016,2019]), ['rgdpe','rgdpo']]\n",
        "#\n",
        "pwt.loc[(([\"CHN\", \"USA\"], [2016,2019])), ['rgdpe','rgdpo']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "除了通常的排序以外，由于有了二级索引，如果按索引排序，两级索引变量是同时排序的："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.sort_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可以对两级索引以列表的形式分别设定排序的顺序。例如，先将国家代码按字母升序，然后将年降序："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.sort_index(ascending=[True, False])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `stack` 和 `unstack`\n",
        "\n",
        "数据有“长（long）”和“宽（wide）”两种组织方式，Penn World Table 是以“长”的形式保存的。有时候需要在两种数据格式之间进行转换，就需要用到`df.stack()`和`df.unstack()`函数。\n",
        "\n",
        "注意，`df.unstack()`函数的参数`level=`，设置为哪一级索引，便生成为列。默认在最后一级索引上转换，即年，因此列便为年，行为国家，反之，列为国家，行为年。如下面例子所示，为了简便只保留了三个国家5年的数据："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt_sub = pwt.loc[([\"CHN\", \"KOR\", \"USA\"], slice(2015, None)), [\"rgdpe\", \"pop\"]]\n",
        "# \n",
        "pwt_sub_wide = pwt_sub.unstack(level=-1)\n",
        "# pwt_sub.unstack(level=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "要获得长格式的数据，使用`df.stack()`即可："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt_sub_wide.stack(future_stack=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "当我们从一些数据库下载数据时，常见形式为列为不同时期相同变量的值。例如，从世界银行下载人均GDP和人口数据："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import wbgapi as wb\n",
        "df = wb.data.DataFrame(series=['NY.GDP.PCAP.CD', \"SP.POP.TOTL\"], \n",
        "                                #time=range(2017,2020),\n",
        "                                time=['YR2017','YR2018','YR2019'],\n",
        "                                 numericTimeKeys=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "下载的数据`df`索引是“economy - series”，每一年数据一列。我们希望序列成为列变量，时间成为索引。我们可以先对数据进行转置成宽格式的数据，然后再在国家层面堆叠，使其成为索引，再交换索引排序得到通常的情况："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.T.stack(level=0, future_stack=True).swaplevel().sort_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "另外，stack不是唯一的方法，也可以使用`df.melt()`结合`df.pivot_table()`函数来实现："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_reset = df.reset_index()\n",
        "df_long = df_reset.melt(id_vars=['economy', 'series'], var_name='year', value_name='value')\n",
        "df_long.pivot_table(index=['economy', 'year'], columns='series', values='value')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pandas中的分组计算（`groupby`）\n",
        "\n",
        "Pandas 的分组（`groupby()`）方法按照“分割-应用-组合（split-apply-combine）”的原理，创建一个 groupby 对象，可以应用各种方法来聚合、转换或过滤数据。更多介绍参见Pandas官方文档[Group by: split-apply-combine](https://pandas.pydata.org/docs/user_guide/groupby.html)。\n",
        "\n",
        "选择合适的方法：\n",
        "\n",
        "- 如果你的操作只是简单的统计（如求和、平均值），优先使用聚合方法，它们通常效率最高。\n",
        "- 如果需要返回与原始 DataFrame 相同长度的结果，例如进行组内标准化，使用转换方法。\n",
        "- 如果需要根据组的属性来决定保留或丢弃整个组，使用过滤方法。\n",
        "- 当以上方法都无法满足需求时，或者需要执行更复杂的自定义逻辑时，使用**apply()**方法。\n",
        "\n",
        "#### 聚合方法（Aggregation Methods）\n",
        "\n",
        "聚合方法将每个组的数据压缩成一个单一的值，是最常用的`groupby`操作，例如`mean()`,`sum()`,`count()`,`size()`,`min()`,`max()`,`std()`,`var()`,`median()`等常见的统计量，或者`first()`,`last()`,`nth(n)`等获取第一个、最好一个或第n个值：\n",
        "\n",
        "\n",
        "**索引**\n",
        "\n",
        "例如，根据索引计算世界人口，先在索引上分组，然后使用`.sum()`函数："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.groupby(level=1)['pop'].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`avh`变量度量了“Average annual hours worked by persons engaged”,让我们分组计算平均，得到按年和按国家平均"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "avh = pwt[pwt['avh'].notna()]\n",
        "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
        "avh.groupby(level=1)['avh'].mean().sort_values(ascending=False).plot(kind='line', ax=ax[0])\n",
        "ax[0].set_xlabel(\"\")\n",
        "ax[0].set_ylabel(\"Average annual hours worked by persons engaged\")\n",
        "avh.groupby(level=0)['avh'].mean().sort_values(ascending=False)[:25].plot(kind='bar', ax=ax[1])\n",
        "ax[1].set_xlabel(\"\")\n",
        "ax[1].set_ylabel(\"Average annual hours worked by persons engaged\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最常见的是按变量进行分组，例如，按国家名`country`分组，最后一个观测值："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.groupby(by=['country']).last()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 转换方法（Transformation Methods）\n",
        "\n",
        "- `transform(func)`: 对每个组应用函数，并将结果广播回原始 DataFrame 的形状。\n",
        "- `rank(method='average')`: 计算组内排名。\n",
        "- `fillna(value)`: 在组内填充缺失值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "avh.groupby(level=1)['avh'].transform('mean')\n",
        "avh.groupby(level=1)['avh'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "注意，转换与聚合的区别,转换将生成的值与原数据观测值一样多，这里是3492个，而聚合只有70个。\n",
        "\n",
        "`.transform()`方法可以与`lambda`函数相结合，例如："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.select_dtypes(np.number).groupby(level=0).transform(lambda x: (x - x.mean())/x.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 过滤方法（Filtration Methods）\n",
        "\n",
        "过滤方法会根据每个组的某个条件来排除整个组。\n",
        "\n",
        "- filter(func): 根据一个返回布尔值的函数来过滤组。如果函数对一个组返回 True，则保留该组；否则，删除该组。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.groupby(level=0).filter(lambda x: x['pop'].mean() > 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 应用方法（Application Methods）\n",
        "apply() 方法是最通用的方法，它允许你对每个组应用任何自定义函数。这个函数可以执行聚合、转换或过滤操作，或者任何更复杂的逻辑。\n",
        "\n",
        "- apply(func): 将一个自定义函数应用于每个组。函数的返回值可以是 Series、DataFrame 或标量。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}